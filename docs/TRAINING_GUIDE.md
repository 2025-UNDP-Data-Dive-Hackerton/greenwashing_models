# ğŸ“ ê·¸ë¦°ì›Œì‹± íƒì§€ ëª¨ë¸ í›ˆë ¨ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [í›ˆë ¨ ê°œìš”](#-í›ˆë ¨-ê°œìš”)
2. [ì‚¬ì „ ì¤€ë¹„](#-ì‚¬ì „-ì¤€ë¹„)
3. [í›ˆë ¨ ì‹¤í–‰](#-í›ˆë ¨-ì‹¤í–‰)
4. [ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•](#-ëª¨ë¸-ì»¤ìŠ¤í„°ë§ˆì´ì§•)
5. [ì„±ëŠ¥ íŠœë‹](#-ì„±ëŠ¥-íŠœë‹)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

## ğŸ¯ í›ˆë ¨ ê°œìš”

### **ì™œ ëª¨ë¸ì„ ì¬í›ˆë ¨í•˜ë‚˜ìš”?**
- âœ… **ìƒˆë¡œìš´ ë°ì´í„°** ì¶”ê°€ ì‹œ (2024ë…„ ì´í›„ ë°ì´í„°)
- âœ… **í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸** (ìƒˆë¡œìš´ í™˜ê²½ ìš©ì–´)
- âœ… **ì„±ëŠ¥ ê°œì„ ** (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)
- âœ… **ë„ë©”ì¸ íŠ¹í™”** (íŠ¹ì • êµ­ê°€/ë¶„ì•¼ ì§‘ì¤‘)

### **í›ˆë ¨ë˜ëŠ” 3ê°€ì§€ ëª¨ë¸**
1. **ğŸ”¤ í…ìŠ¤íŠ¸ ë¶ˆì¼ì¹˜ íƒì§€**: TF-IDF + Logistic Regression
2. **ğŸ“ˆ íˆ¬ì íŒ¨í„´ ì´ìƒ íƒì§€**: Isolation Forest
3. **ğŸ¯ ë§ˆì»¤ ì¸í”Œë ˆì´ì…˜ íƒì§€**: Gradient Boosting

## ğŸš€ ì‚¬ì „ ì¤€ë¹„

### **1. ë°ì´í„° í™•ì¸**
```bash
# CRS ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ (ìƒìœ„ í´ë”)
ls ../crs_data.csv

# ì „ì²˜ë¦¬ëœ ë°ì´í„° ìƒì„± (í•„ìˆ˜)
python scripts/preprocess_crs_data.py
# ê²°ê³¼: crs_processed.csv (121MB, 768,314ê°œ í”„ë¡œì íŠ¸)
```

### **2. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­**
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 4GB RAM (8GB ê¶Œì¥)
- **ë””ìŠ¤í¬**: 10GB ì—¬ìœ  ê³µê°„
- **ì‹œê°„**: ì „ì²´ í›ˆë ¨ ì•½ 10-15ë¶„

### **3. í™˜ê²½ ì„¤ì •**
```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# Python ë²„ì „ í™•ì¸ (3.8+ í•„ìš”)
python --version
```

## âš¡ í›ˆë ¨ ì‹¤í–‰

### **ê¸°ë³¸ í›ˆë ¨**
```bash
# ì „ì²´ ëª¨ë¸ í›ˆë ¨ (ê¸°ë³¸ ì„¤ì •)
python scripts/train_models.py

# ì˜ˆìƒ ê²°ê³¼:
# - í…ìŠ¤íŠ¸ ëª¨ë¸: AUC 0.9848
# - ì´ìƒ íƒì§€: 5.0% íƒì§€ìœ¨
# - ì¸í”Œë ˆì´ì…˜ ëª¨ë¸: AUC 0.3036
```


## ğŸ”§ ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### **1. í™˜ê²½ í‚¤ì›Œë“œ ìˆ˜ì •**
```python
# models/model_config.json í¸ì§‘
{
  "environmental_keywords": [
    "climate", "green", "renewable",
    "ìƒˆë¡œìš´í‚¤ì›Œë“œ1", "ìƒˆë¡œìš´í‚¤ì›Œë“œ2"  # ì¶”ê°€
  ]
}
```

### **2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
```python
# scripts/train_models.pyì—ì„œ ìˆ˜ì • ê°€ëŠ¥

# í…ìŠ¤íŠ¸ ëª¨ë¸
model = LogisticRegression(
    random_state=42,
    max_iter=2000,        # ì¦ê°€
    C=0.1,               # ì •ê·œí™” ê°•í™”
    class_weight='balanced'
)

# ì´ìƒ íƒì§€ ëª¨ë¸
model = IsolationForest(
    contamination=0.03,   # 3%ë¡œ ê°ì†Œ
    n_estimators=200,     # íŠ¸ë¦¬ ìˆ˜ ì¦ê°€
    random_state=42
)

# ì¸í”Œë ˆì´ì…˜ ëª¨ë¸
model = GradientBoostingClassifier(
    n_estimators=200,     # íŠ¸ë¦¬ ìˆ˜ ì¦ê°€
    learning_rate=0.05,   # í•™ìŠµë¥  ê°ì†Œ
    max_depth=5,          # ê¹Šì´ ì¦ê°€
    random_state=42
)
```

### **3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**
```python
# scripts/train_models.pyì—ì„œ í”¼ì²˜ ì¶”ê°€

def create_custom_features(self, df):
    """ì»¤ìŠ¤í…€ í”¼ì²˜ ìƒì„±"""
    # ìƒˆë¡œìš´ í”¼ì²˜ ì•„ì´ë””ì–´ë“¤
    df['project_complexity'] = df['ProjectTitle'].str.len()
    df['multi_country'] = df['RecipientName'].str.contains(',').astype(int)
    df['recent_project'] = (df['Year'] >= 2020).astype(int)
    
    return df
```

## ğŸ“Š ì„±ëŠ¥ íŠœë‹

### **ì„±ëŠ¥ ì§€í‘œ í•´ì„**

#### **í…ìŠ¤íŠ¸ ëª¨ë¸ (AUC ê¸°ì¤€)**
- **0.95+ (ìš°ìˆ˜)**: í…ìŠ¤íŠ¸-ë§ˆì»¤ ë¶ˆì¼ì¹˜ë¥¼ ì˜ íƒì§€
- **0.90-0.95 (ì–‘í˜¸)**: ëŒ€ë¶€ë¶„ì˜ ë¶ˆì¼ì¹˜ íƒì§€ ê°€ëŠ¥
- **0.90 ë¯¸ë§Œ**: í‚¤ì›Œë“œë‚˜ ë°ì´í„° í’ˆì§ˆ ì ê²€ í•„ìš”

#### **ì´ìƒ íƒì§€ (íƒì§€ìœ¨ ê¸°ì¤€)**
- **3-7% (ì ì •)**: í•©ë¦¬ì ì¸ ì´ìƒì¹˜ ë¹„ìœ¨
- **10% ì´ìƒ**: ë„ˆë¬´ ë¯¼ê°í•¨, contamination ì¡°ì • í•„ìš”
- **1% ë¯¸ë§Œ**: ë„ˆë¬´ ë³´ìˆ˜ì , ì‹¤ì œ ì´ìƒì¹˜ ë†“ì¹  ìˆ˜ ìˆìŒ

#### **ì¸í”Œë ˆì´ì…˜ ëª¨ë¸ (AUC ê¸°ì¤€)**
- **0.90+ (ìš°ìˆ˜)**: êµ­ê°€ë³„ ì¸í”Œë ˆì´ì…˜ ì˜ êµ¬ë¶„
- **0.80-0.90 (ì–‘í˜¸)**: ëŒ€ë¶€ë¶„ì˜ ì¸í”Œë ˆì´ì…˜ íƒì§€
- **0.80 ë¯¸ë§Œ**: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê°œì„  í•„ìš”

### **ì„±ëŠ¥ ê°œì„  íŒ**

#### **1. ë°ì´í„° í’ˆì§ˆ í–¥ìƒ**
```python
# ë” ì—„ê²©í•œ ë°ì´í„° ì •ì œ
df = df[df['USD_Commitment'] > 1000]  # ìµœì†Œ íˆ¬ìì•¡ í•„í„°
df = df[df['ProjectTitle'].str.len() > 10]  # ì œëª© ê¸¸ì´ í•„í„°
```

#### **2. ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì¡°ì •**
```python
# predict_greenwashing.pyì—ì„œ ê°€ì¤‘ì¹˜ ìˆ˜ì •
final_score = (
    0.4 * text_score +      # í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ì¦ê°€
    0.3 * anomaly_score +   # ì´ìƒ íƒì§€ ê°€ì¤‘ì¹˜
    0.3 * inflation_score   # ì¸í”Œë ˆì´ì…˜ ê°€ì¤‘ì¹˜
)
```

#### **3. êµì°¨ ê²€ì¦**
```python
# ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')
print(f"êµì°¨ ê²€ì¦ AUC: {scores.mean():.4f} Â± {scores.std():.4f}")
```



### **ì„±ëŠ¥ ìµœì í™”**

#### **1. ë©€í‹°í”„ë¡œì„¸ì‹± í™œìš©**
```python
# sklearn ëª¨ë¸ì—ì„œ ë³‘ë ¬ ì²˜ë¦¬
model = LogisticRegression(n_jobs=-1)  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
model = IsolationForest(n_jobs=-1)
```

#### **2. ì¡°ê¸° ì¢…ë£Œ**
```python
# Gradient Boostingì—ì„œ ì¡°ê¸° ì¢…ë£Œ
model = GradientBoostingClassifier(
    n_estimators=1000,
    validation_fraction=0.1,
    n_iter_no_change=10,  # 10íšŒ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨
    tol=1e-4
)
```

## ğŸ‰ í›ˆë ¨ ì™„ë£Œ í›„ í™•ì¸ì‚¬í•­

### **1. ëª¨ë¸ íŒŒì¼ í™•ì¸**
```bash
ls models/
# ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìˆì–´ì•¼ í•¨:
# - text_inconsistency_model.pkl
# - tfidf_vectorizer.pkl
# - investment_anomaly_model.pkl
# - anomaly_scaler.pkl
# - marker_inflation_model.pkl
# - model_config.json
```

### **2. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**
```bash
# ì˜ˆì¸¡ ì‹¤í–‰ìœ¼ë¡œ ëª¨ë¸ ì‘ë™ í™•ì¸
python scripts/predict_greenwashing.py

# ê²°ê³¼ íŒŒì¼ í™•ì¸
ls log_commitment.csv
```

### **3. í†µê³„ ìƒì„±**
```bash
# í†µê³„ ìƒì„±ìœ¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í™•ì¸
python scripts/generate_statistics.py

# í†µê³„ íŒŒì¼ë“¤ í™•ì¸
ls *.csv *.json analysis_report.md
```

