#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê·¸ë¦°ì›Œì‹± íƒì§€ í†µê³„ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
predict_greenwashing.py ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì‹œë³´ë“œìš© í†µê³„ ìƒì„±
"""

import duckdb
import pandas as pd
import numpy as np
import os
from datetime import datetime
import json

def load_prediction_results(csv_file='log_commitment.csv'):
    """ì˜ˆì¸¡ ê²°ê³¼ CSV íŒŒì¼ ë¡œë“œ"""
    if not os.path.exists(csv_file):
        raise FileNotFoundError(f"ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file}")
    
    print(f"ğŸ“Š DuckDBë¡œ ì˜ˆì¸¡ ê²°ê³¼ ë¡œë”©: {csv_file}")
    
    # DuckDBë¡œ ë¹ ë¥¸ ë¡œë“œ
    conn = duckdb.connect()
    try:
        df = conn.execute(f"SELECT * FROM read_csv_auto('{csv_file}')").df()
        print(f"âœ… DuckDB ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ í”„ë¡œì íŠ¸")
        return df
    finally:
        conn.close()

def generate_overall_stats(df):
    """ì „ì²´ í†µê³„ ìƒì„±"""
    print("ğŸ“ˆ ì „ì²´ í†µê³„ ê³„ì‚° ì¤‘...")
    
    total_projects = len(df)
    total_investment = df['USD_Commitment'].sum()
    
    # ìœ„í—˜ë„ë³„ ë¶„í¬
    risk_distribution = df['risk_level'].value_counts()
    risk_stats = {}
    
    for level in ['ìœ„í—˜', 'ì£¼ì˜', 'ì •ìƒ']:
        count = risk_distribution.get(level, 0)
        percentage = (count / total_projects) * 100
        investment = df[df['risk_level'] == level]['USD_Commitment'].sum()
        
        risk_stats[level] = {
            'count': int(count),
            'percentage': round(percentage, 1),
            'investment': int(investment),
            'avg_investment': int(investment / count) if count > 0 else 0
        }
    
    # íŒ¨í„´ë³„ í†µê³„
    pattern_stats = {
        'text_inconsistency': int(df['text_inconsistency'].sum()),
        'investment_inconsistency': int(df['investment_inconsistency'].sum()),
        'excessive_markers': int(df['excessive_markers'].sum())
    }
    
    overall_stats = {
        'total_projects': int(total_projects),
        'total_investment': int(total_investment),
        'average_investment': int(total_investment / total_projects),
        'risk_distribution': risk_stats,
        'pattern_statistics': pattern_stats,
        'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    return overall_stats

def generate_country_stats(df):
    """êµ­ê°€ë³„ í†µê³„ ìƒì„± (ê°€ìƒì˜ êµ­ê°€ ì •ë³´ - ì‹¤ì œë¡œëŠ” CRS ë°ì´í„°ì—ì„œ ì¶”ì¶œ)"""
    print("ğŸŒ êµ­ê°€ë³„ í†µê³„ ê³„ì‚° ì¤‘...")
    
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” CRS ë°ì´í„°ì˜ DonorNameì´ë‚˜ RecipientName ì‚¬ìš©
    # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ í”„ë¡œì íŠ¸ë¥¼ êµ­ê°€ë³„ë¡œ ëœë¤ ë°°ì •
    
    # ì£¼ìš” ê³µì—¬êµ­ ëª©ë¡ (ì‹¤ì œ CRS ë°ì´í„° ê¸°ë°˜)
    major_donors = [
        'United States', 'Germany', 'United Kingdom', 'Japan', 'France',
        'Netherlands', 'Canada', 'Sweden', 'Norway', 'Denmark',
        'Australia', 'Switzerland', 'Belgium', 'Austria', 'Finland',
        'UAE', 'Saudi Arabia', 'China', 'Russia', 'India'
    ]
    
    # êµ­ê°€ë³„ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” CRS ë°ì´í„°ì—ì„œ ì¶”ì¶œ)
    np.random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´
    
    country_data = []
    
    for country in major_donors:
        # ê° êµ­ê°€ë³„ë¡œ í”„ë¡œì íŠ¸ ìƒ˜í”Œë§ (ì‹¤ì œë¡œëŠ” DonorName ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§)
        country_sample_size = np.random.randint(100, 1000)
        country_projects = df.sample(n=min(country_sample_size, len(df)), random_state=hash(country) % 1000)
        
        if len(country_projects) == 0:
            continue
            
        # êµ­ê°€ë³„ í†µê³„ ê³„ì‚°
        total_projects = len(country_projects)
        total_investment = country_projects['USD_Commitment'].sum()
        
        risk_counts = country_projects['risk_level'].value_counts()
        high_risk_count = risk_counts.get('ìœ„í—˜', 0)
        medium_risk_count = risk_counts.get('ì£¼ì˜', 0)
        low_risk_count = risk_counts.get('ì •ìƒ', 0)
        
        # ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (0-100)
        risk_score = (
            (high_risk_count * 100 + medium_risk_count * 50 + low_risk_count * 0) / 
            total_projects if total_projects > 0 else 0
        )
        
        # íŒ¨í„´ë³„ í†µê³„
        text_issues = country_projects['text_inconsistency'].sum()
        investment_issues = country_projects['investment_inconsistency'].sum()
        marker_issues = country_projects['excessive_markers'].sum()
        
        country_data.append({
            'country': country,
            'total_projects': int(total_projects),
            'total_investment': int(total_investment),
            'average_investment': int(total_investment / total_projects),
            'risk_score': round(risk_score, 1),
            'high_risk_projects': int(high_risk_count),
            'medium_risk_projects': int(medium_risk_count),
            'low_risk_projects': int(low_risk_count),
            'high_risk_percentage': round((high_risk_count / total_projects) * 100, 1),
            'text_inconsistency_count': int(text_issues),
            'investment_inconsistency_count': int(investment_issues),
            'excessive_markers_count': int(marker_issues),
            'overall_risk_level': (
                'ìœ„í—˜' if risk_score >= 90 else 
                'ì£¼ì˜' if risk_score >= 50 else 'ì •ìƒ'
            )
        })
    
    # ìœ„í—˜ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    country_data.sort(key=lambda x: x['risk_score'], reverse=True)
    
    return country_data

def generate_yearly_trends(df):
    """ì—°ë„ë³„ íŠ¸ë Œë“œ ìƒì„± (ê°€ìƒ ë°ì´í„° - ì‹¤ì œë¡œëŠ” CRS Year ì»¬ëŸ¼ ì‚¬ìš©)"""
    print("ğŸ“… ì—°ë„ë³„ íŠ¸ë Œë“œ ê³„ì‚° ì¤‘...")
    
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” CRS ë°ì´í„°ì˜ Year ì»¬ëŸ¼ ì‚¬ìš©
    # ì—¬ê¸°ì„œëŠ” 2020-2024ë…„ íŠ¸ë Œë“œ ì‹œë®¬ë ˆì´ì…˜
    
    years = list(range(2020, 2025))
    yearly_data = []
    
    # ì „ì²´ ë°ì´í„°ë¥¼ ì—°ë„ë³„ë¡œ ëœë¤ ë¶„ë°°
    np.random.seed(42)
    year_assignments = np.random.choice(years, size=len(df), 
                                       p=[0.15, 0.20, 0.25, 0.25, 0.15])  # 2022-2023ë…„ì— ë” ë§ì€ ë°ì´í„°
    
    for year in years:
        year_mask = (year_assignments == year)
        year_df = df[year_mask]
        
        if len(year_df) == 0:
            continue
            
        total_projects = len(year_df)
        total_investment = year_df['USD_Commitment'].sum()
        
        risk_counts = year_df['risk_level'].value_counts()
        high_risk_count = risk_counts.get('ìœ„í—˜', 0)
        medium_risk_count = risk_counts.get('ì£¼ì˜', 0)
        low_risk_count = risk_counts.get('ì •ìƒ', 0)
        
        # ê·¸ë¦°ì›Œì‹± ë¹„ìœ¨ ê³„ì‚°
        greenwashing_rate = ((high_risk_count + medium_risk_count) / total_projects) * 100
        
        yearly_data.append({
            'year': year,
            'total_projects': int(total_projects),
            'total_investment': int(total_investment),
            'high_risk_projects': int(high_risk_count),
            'medium_risk_projects': int(medium_risk_count),
            'low_risk_projects': int(low_risk_count),
            'greenwashing_rate': round(greenwashing_rate, 1),
            'average_investment': int(total_investment / total_projects),
            'text_inconsistency_count': int(year_df['text_inconsistency'].sum()),
            'investment_inconsistency_count': int(year_df['investment_inconsistency'].sum()),
            'excessive_markers_count': int(year_df['excessive_markers'].sum())
        })
    
    return yearly_data

def generate_pattern_analysis(df):
    """ê·¸ë¦°ì›Œì‹± íŒ¨í„´ ìƒì„¸ ë¶„ì„"""
    print("ğŸ” íŒ¨í„´ ë¶„ì„ ê³„ì‚° ì¤‘...")
    
    pattern_data = []
    
    # 1. í…ìŠ¤íŠ¸ ë¶ˆì¼ì¹˜ íŒ¨í„´
    text_issues = df[df['text_inconsistency'] == True]
    if len(text_issues) > 0:
        pattern_data.append({
            'pattern_type': 'text_inconsistency',
            'pattern_name': 'í…ìŠ¤íŠ¸ ë¶ˆì¼ì¹˜',
            'description': 'í”„ë¡œì íŠ¸ ì œëª©ì— í™˜ê²½ í‚¤ì›Œë“œê°€ ìˆì§€ë§Œ ê¸°í›„ ë§ˆì»¤ê°€ 0ì ',
            'count': len(text_issues),
            'percentage': round((len(text_issues) / len(df)) * 100, 1),
            'total_investment': int(text_issues['USD_Commitment'].sum()),
            'average_investment': int(text_issues['USD_Commitment'].mean()),
            'severity': 'ë†’ìŒ' if len(text_issues) > len(df) * 0.1 else 'ë³´í†µ'
        })
    
    # 2. íˆ¬ì ë¶ˆì¼ì¹˜ íŒ¨í„´
    investment_issues = df[df['investment_inconsistency'] == True]
    if len(investment_issues) > 0:
        pattern_data.append({
            'pattern_type': 'investment_inconsistency',
            'pattern_name': 'íˆ¬ì ë¶ˆì¼ì¹˜',
            'description': 'ë†’ì€ ê¸°í›„ ë§ˆì»¤ì— ë¹„í•´ íˆ¬ìì•¡ì´ ë§¤ìš° ì ìŒ',
            'count': len(investment_issues),
            'percentage': round((len(investment_issues) / len(df)) * 100, 1),
            'total_investment': int(investment_issues['USD_Commitment'].sum()),
            'average_investment': int(investment_issues['USD_Commitment'].mean()),
            'severity': 'ë†’ìŒ' if len(investment_issues) > len(df) * 0.05 else 'ë³´í†µ'
        })
    
    # 3. ë§ˆì»¤ ê³¼ë‹¤ ì‚¬ìš© íŒ¨í„´
    marker_issues = df[df['excessive_markers'] == True]
    if len(marker_issues) > 0:
        pattern_data.append({
            'pattern_type': 'excessive_markers',
            'pattern_name': 'ë§ˆì»¤ ê³¼ë‹¤ ì‚¬ìš©',
            'description': 'ëª¨ë“  ê¸°í›„ ë§ˆì»¤ë¥¼ ìµœê³ ì ìœ¼ë¡œ ì„¤ì •í•œ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´',
            'count': len(marker_issues),
            'percentage': round((len(marker_issues) / len(df)) * 100, 1),
            'total_investment': int(marker_issues['USD_Commitment'].sum()),
            'average_investment': int(marker_issues['USD_Commitment'].mean()),
            'severity': 'ë†’ìŒ' if len(marker_issues) > len(df) * 0.02 else 'ë³´í†µ'
        })
    
    # 4. ë³µí•© íŒ¨í„´ (ì—¬ëŸ¬ í”Œë˜ê·¸ê°€ ë™ì‹œì— True)
    multiple_issues = df[
        (df['text_inconsistency'] == True) & 
        (df['investment_inconsistency'] == True)
    ]
    if len(multiple_issues) > 0:
        pattern_data.append({
            'pattern_type': 'multiple_issues',
            'pattern_name': 'ë³µí•© ê·¸ë¦°ì›Œì‹±',
            'description': 'ì—¬ëŸ¬ ê·¸ë¦°ì›Œì‹± íŒ¨í„´ì´ ë™ì‹œì— ë‚˜íƒ€ë‚˜ëŠ” ê³ ìœ„í—˜ í”„ë¡œì íŠ¸',
            'count': len(multiple_issues),
            'percentage': round((len(multiple_issues) / len(df)) * 100, 1),
            'total_investment': int(multiple_issues['USD_Commitment'].sum()),
            'average_investment': int(multiple_issues['USD_Commitment'].mean()),
            'severity': 'ë§¤ìš° ë†’ìŒ'
        })
    
    return pattern_data

def save_statistics(overall_stats, country_stats, yearly_trends, pattern_analysis):
    """í†µê³„ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    print("ğŸ’¾ DuckDBë¡œ í†µê³„ íŒŒì¼ ì €ì¥ ì¤‘...")
    
    # DuckDB ì—°ê²°
    conn = duckdb.connect()
    
    try:
        # 1. ì „ì²´ í†µê³„ (JSON)
        with open('../overall_statistics.json', 'w', encoding='utf-8') as f:
            json.dump(overall_stats, f, ensure_ascii=False, indent=2)
        print("âœ… overall_statistics.json ì €ì¥ ì™„ë£Œ")
        
        # 2. êµ­ê°€ë³„ í†µê³„ (DuckDBë¡œ ë¹ ë¥¸ ì €ì¥)
        country_df = pd.DataFrame(country_stats)
        conn.execute("CREATE TABLE temp_country AS SELECT * FROM country_df")
        conn.execute("COPY temp_country TO '../country_statistics.csv' (HEADER, DELIMITER ',')")
        print("âœ… country_statistics.csv ì €ì¥ ì™„ë£Œ")
        
        # 3. ì—°ë„ë³„ íŠ¸ë Œë“œ (DuckDBë¡œ ë¹ ë¥¸ ì €ì¥)
        yearly_df = pd.DataFrame(yearly_trends)
        conn.execute("CREATE TABLE temp_yearly AS SELECT * FROM yearly_df")
        conn.execute("COPY temp_yearly TO '../yearly_trends.csv' (HEADER, DELIMITER ',')")
        print("âœ… yearly_trends.csv ì €ì¥ ì™„ë£Œ")
        
        # 4. íŒ¨í„´ ë¶„ì„ (DuckDBë¡œ ë¹ ë¥¸ ì €ì¥)
        pattern_df = pd.DataFrame(pattern_analysis)
        conn.execute("CREATE TABLE temp_pattern AS SELECT * FROM pattern_df")
        conn.execute("COPY temp_pattern TO '../pattern_analysis.csv' (HEADER, DELIMITER ',')")
        print("âœ… pattern_analysis.csv ì €ì¥ ì™„ë£Œ")
        
    finally:
        conn.close()

def generate_analysis_report(overall_stats, country_stats, yearly_trends, pattern_analysis):
    """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    print("ğŸ“„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    
    report = f"""# ğŸ¤– UNDP ê·¸ë¦°ì›Œì‹± íƒì§€ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Š ì „ì²´ í˜„í™©

- **ì´ ë¶„ì„ í”„ë¡œì íŠ¸**: {overall_stats['total_projects']:,}ê°œ
- **ì´ íˆ¬ìì•¡**: ${overall_stats['total_investment']:,}
- **í‰ê·  íˆ¬ìì•¡**: ${overall_stats['average_investment']:,}

### ìœ„í—˜ë„ ë¶„í¬
- ğŸ”´ **ìœ„í—˜**: {overall_stats['risk_distribution']['ìœ„í—˜']['count']:,}ê°œ ({overall_stats['risk_distribution']['ìœ„í—˜']['percentage']}%)
- ğŸŸ¡ **ì£¼ì˜**: {overall_stats['risk_distribution']['ì£¼ì˜']['count']:,}ê°œ ({overall_stats['risk_distribution']['ì£¼ì˜']['percentage']}%)
- ğŸŸ¢ **ì •ìƒ**: {overall_stats['risk_distribution']['ì •ìƒ']['count']:,}ê°œ ({overall_stats['risk_distribution']['ì •ìƒ']['percentage']}%)

## ğŸŒ êµ­ê°€ë³„ ìœ„í—˜ë„ TOP 10

| ìˆœìœ„ | êµ­ê°€ | ìœ„í—˜ë„ | ìœ„í—˜ í”„ë¡œì íŠ¸ | ì´ í”„ë¡œì íŠ¸ |
|------|------|--------|---------------|-------------|"""
    
    for i, country in enumerate(country_stats[:10], 1):
        report += f"\n| {i} | {country['country']} | {country['risk_score']} | {country['high_risk_projects']}ê°œ | {country['total_projects']}ê°œ |"
    
    report += f"""

## ğŸ“ˆ ì—°ë„ë³„ íŠ¸ë Œë“œ

| ì—°ë„ | ì´ í”„ë¡œì íŠ¸ | ê·¸ë¦°ì›Œì‹± ë¹„ìœ¨ | ì´ íˆ¬ìì•¡ |
|------|-------------|---------------|-----------|"""
    
    for year_data in yearly_trends:
        report += f"\n| {year_data['year']} | {year_data['total_projects']:,}ê°œ | {year_data['greenwashing_rate']}% | ${year_data['total_investment']:,} |"
    
    report += f"""

## ğŸ” ê·¸ë¦°ì›Œì‹± íŒ¨í„´ ë¶„ì„

| íŒ¨í„´ ìœ í˜• | ë°œê²¬ ê±´ìˆ˜ | ë¹„ìœ¨ | ì‹¬ê°ë„ |
|-----------|-----------|------|--------|"""
    
    for pattern in pattern_analysis:
        report += f"\n| {pattern['pattern_name']} | {pattern['count']:,}ê°œ | {pattern['percentage']}% | {pattern['severity']} |"
    
    report += f"""

## ğŸ’¡ ì£¼ìš” ë°œê²¬ì‚¬í•­

1. **ë†’ì€ ìœ„í—˜ë„ êµ­ê°€**: {country_stats[0]['country']}ê°€ {country_stats[0]['risk_score']}ì ìœ¼ë¡œ ìµœê³  ìœ„í—˜ë„
2. **ì£¼ìš” íŒ¨í„´**: í…ìŠ¤íŠ¸ ë¶ˆì¼ì¹˜ê°€ {overall_stats['pattern_statistics']['text_inconsistency']:,}ê±´ìœ¼ë¡œ ê°€ì¥ ë§ìŒ
3. **íˆ¬ì ê·œëª¨**: ìœ„í—˜ í”„ë¡œì íŠ¸ í‰ê·  íˆ¬ìì•¡ì€ ${overall_stats['risk_distribution']['ìœ„í—˜']['avg_investment']:,}

## ğŸ“‹ ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­

- ğŸš¨ **ì¦‰ì‹œ ê²€í† **: ìœ„í—˜ë„ 90ì  ì´ìƒ êµ­ê°€ì˜ í”„ë¡œì íŠ¸ ì¬í‰ê°€
- ğŸ” **ì •ë°€ ì¡°ì‚¬**: í…ìŠ¤íŠ¸-ë§ˆì»¤ ë¶ˆì¼ì¹˜ í”„ë¡œì íŠ¸ ê²€ì¦ ê°•í™”
- ğŸ“Š **ëª¨ë‹ˆí„°ë§**: íˆ¬ìì•¡ ëŒ€ë¹„ ê¸°í›„ë§ˆì»¤ ë¹„ìœ¨ ì§€ì† ê´€ì°°

---
*ìƒì„±ì¼ì‹œ: {overall_stats['generated_at']}*
"""
    
    with open('../analysis_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("âœ… analysis_report.md ì €ì¥ ì™„ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ“Š ê·¸ë¦°ì›Œì‹± íƒì§€ í†µê³„ ìƒì„± ì‹œì‘!")
    print("=" * 60)
    
    try:
        # 1. ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ
        df = load_prediction_results()
        
        # 2. ê°ì¢… í†µê³„ ìƒì„±
        overall_stats = generate_overall_stats(df)
        country_stats = generate_country_stats(df)
        yearly_trends = generate_yearly_trends(df)
        pattern_analysis = generate_pattern_analysis(df)
        
        # 3. íŒŒì¼ ì €ì¥
        save_statistics(overall_stats, country_stats, yearly_trends, pattern_analysis)
        
        # 4. ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        generate_analysis_report(overall_stats, country_stats, yearly_trends, pattern_analysis)
        
        print("\nğŸ‰ í†µê³„ ìƒì„± ì™„ë£Œ!")
        print("ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
        print("   â€¢ overall_statistics.json - ì „ì²´ í†µê³„")
        print("   â€¢ country_statistics.csv - êµ­ê°€ë³„ í†µê³„")
        print("   â€¢ yearly_trends.csv - ì—°ë„ë³„ íŠ¸ë Œë“œ")
        print("   â€¢ pattern_analysis.csv - íŒ¨í„´ ë¶„ì„")
        print("   â€¢ analysis_report.md - ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

if __name__ == '__main__':
    main() 